{"cells":[{"source":["# import os, glob, shutil\n","import os, sys\n","import cv2\n","import numpy as np\n","import uuid\n","import tensorflow as tf\n","from skimage.io import imread, imsave, imshow\n","from PIL import Image, ImageTk\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","from core.imageprep import random_crop, crop_generator, random_crop_batch\n","from core.models import UNet\n","from imutils import paths\n","import itertools\n","\n","#%load_ext autoreload\n","#%autoreload 2\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#load image\n","#path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n","path = \"D:/PerlmutterData/\"\n","imgdir = \"training/cell_membrane/prepdata\"\n","imgpath = os.path.join(path, imgdir)\n","\n","imgpath_all = list(paths.list_images(path))\n","print(imgpath_all[0])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# set parameters\n","seed = 100\n","batch_size = 16\n","validation_split = 0.1\n","training_sample_size = len(imgpath_all)\n","IMG_HEIGHT = 256\n","IMG_WIDTH = 256\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# create argments for data generator\n","data_gen_args = dict(\n","                featurewise_center=True,\n","                featurewise_std_normalization=True,\n","                horizontal_flip=True,\n","                vertical_flip=True,\n","                rotation_range=90.,\n","                width_shift_range=0.1,\n","                height_shift_range=0.1,\n","                shear_range=0.07,\n","                zoom_range=0.2,\n","                validation_split=validation_split, \n","                # fill_mode='constant',\n","                # cval=0.,\n","                # rescale=1.0/255.0,\n","                )\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["image_datagen = ImageDataGenerator(**data_gen_args)\n","label_datagen = ImageDataGenerator(**data_gen_args)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_image_generator = image_datagen.flow_from_directory(\n","    os.path.join(imgpath, 'train/images/'),\n","    class_mode=None,\n","    color_mode='grayscale',\n","    batch_size=batch_size,\n","    subset='training',\n","    seed=seed)\n","\n","train_label_generator = label_datagen.flow_from_directory(\n","    os.path.join(imgpath, 'train/labels'),\n","    class_mode=None,\n","    color_mode='grayscale',\n","    batch_size=batch_size,\n","    subset='training',\n","    seed=seed)\n","\n","valid_image_generator = image_datagen.flow_from_directory(\n","    os.path.join(imgpath, 'train/images/'),\n","    class_mode=None,\n","    color_mode='grayscale',\n","    batch_size=batch_size,\n","    subset='validation',\n","    seed=seed)\n","\n","valid_label_generator = label_datagen.flow_from_directory(\n","    os.path.join(imgpath, 'train/labels'),\n","    class_mode=None,\n","    color_mode='grayscale',\n","    batch_size=batch_size,\n","    subset='validation',\n","    seed=seed)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# merge image and label generator\n","train_generator = zip(train_image_generator, train_label_generator)\n","valid_generator = zip(valid_image_generator, valid_label_generator)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# create folder for saving the model\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# training\n","from keras.callbacks import ModelCheckpoint\n","from datetime import datetime\n","\n","print(\"Start training\")\n","\n","# checkpointer\n","# check folder\n","if not 'model' in os.listdir(path):\n","    os.mkdir(os.path.join(path, 'model'))\n","# set up the checkpointer\n","\n","# model\n","checkpointer = ModelCheckpoint('model_' + datetime.now().strftime(\"%Y_%m_%d_%H_%M\") + '.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","# calculate steps_per_epoch\n","steps_per_epoch = training_sample_size * (1-validation_split) // batch_size\n","print(\"Steps per epoch: {}\".format(steps_per_epoch))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# prepare the model\n","unetmodel = UNet([IMG_HEIGHT, IMG_WIDTH])\n","\n","# train the model\n","unetmodel.fit_generator(generator=train_generator, \n","                    validation_data = valid_generator,\n","                    validation_steps = 20,\n","                    steps_per_epoch = steps_per_epoch,\n","                    epochs = 500, \n","                    verbose=1, \n","                    callbacks=[checkpointer]\n","                    )\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}